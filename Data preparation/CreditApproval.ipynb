{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('D:/My stuff/School/Master/Master Thesis/Data/UCI Machine Learning Repository/Credit approval data set/crx.txt', na_values = \"?\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename target\n",
    "df.rename(columns = {15 : 'Target'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop variables with a low fill rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns with percentage of missings higher than 0.2\n"
     ]
    }
   ],
   "source": [
    "#Drop variables with too many missing values\n",
    "miss_perc = df.isna().sum() / df.shape[0] > 0.2\n",
    "print(f'Dropped {sum(miss_perc)} columns with percentage of missings higher than 0.2')\n",
    "df = df.loc[:, np.invert(miss_perc)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retain only categorical features with two unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 5 categorical features with more or less than 2 unique values\n"
     ]
    }
   ],
   "source": [
    "#Get number of unique values\n",
    "n_unique = df.nunique() #Get number of unique values (missings disregarded)\n",
    "cat_to_drop = (n_unique != 2) & (df.dtypes == 'object').values\n",
    "print(f'Dropping {sum(cat_to_drop)} categorical features with more or less than 2 unique values')\n",
    "df = df.loc[:, np.invert(cat_to_drop)] #Drop the features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "for i in df.columns[df.dtypes == 'object']: #Loop through categorical columns\n",
    "    df[i] = df[i].map({j:k for j, k in zip(df[i].unique(), [0, 1])}, na_action = 'ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications\n",
    "dep_var = 'Target'\n",
    "thres = 0.75 #Arbitrary for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlations\n",
    "indep_vars = list(set(df.columns.to_list()) - set([dep_var])) #Specify the list of independent variables\n",
    "corr_mat = df.corr() #Calculate the correlation matrix\n",
    "dep_cor = corr_mat[dep_var].copy() #Extract the correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 0) #Drop the row with correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 1) #Drop the column with the correlations with the dependent variable\n",
    "corr_mat.values[np.tril_indices_from(corr_mat.values)] = np.nan #Leave only the upper triangle\n",
    "corr_mat = corr_mat.unstack().dropna().reset_index() #Unstack to a table\n",
    "corr_mat.columns = ['Var 1', 'Var 2', 'Corr'] #Rename columns for clarity\n",
    "corr_mat = corr_mat.loc[np.argsort(-corr_mat['Corr'].abs(), ), :].reset_index(drop = True) #Sort in absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 features due to high correlation\n"
     ]
    }
   ],
   "source": [
    "#Drop correlated features\n",
    "n_dropped = 0 #Initiate the number of dropped features\n",
    "for i in corr_mat.index[corr_mat['Corr'].abs() >= thres]: #Loop through all correlations higher than threshold (in absolute value)\n",
    "    var1, var2 = corr_mat.loc[i, 'Var 1'], corr_mat.loc[i, 'Var 2'] #Store variable names\n",
    "    if (var1 not in indep_vars) | (var2 not in indep_vars):\n",
    "        continue #Skip the iteration if one of the variables has already been disregarded\n",
    "    var_types = df.dtypes[[var1, var2]].to_list() #Store variable types\n",
    "    if var_types.count('object') == 1: #If only one of the variables is categorical, retain the numerical one\n",
    "        var_to_drop = [var1, var2][var_types.index('object')] #Store the categorical variable to drop\n",
    "        not_dropped_var = list(set([var1, var2]) - set(var_to_drop))[0] #Store the numerical variable to retain\n",
    "    else:\n",
    "        min_id = np.argmin(dep_cor[corr_mat.loc[i, ['Var 1', 'Var 2']].values].abs()) #Find the id of the variable with the smallest absolute correlation with the dependent variable\n",
    "        var_to_drop = corr_mat.loc[i, f'Var {min_id + 1}'] #Get the name of the variable to be dropped\n",
    "        not_dropped_var = corr_mat.loc[i, f'Var {abs(min_id - 2)}'] #Get the name of the variable that was not dropped (for logging purposes)\n",
    "    indep_vars.remove(var_to_drop) #Drop the variable\n",
    "    print(f'Variable {var_to_drop} dropped due to correlation of {corr_mat.loc[i, \"Corr\"]:.2%} with {not_dropped_var}')\n",
    "    n_dropped += 1\n",
    "print(f'Dropped {n_dropped} features due to high correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out dropped variables\n",
    "df = df.loc[:, indep_vars + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.4,\n",
       " 1: 5.71,\n",
       " 2: 2.25,\n",
       " 7: 2.05,\n",
       " 8: 2.3,\n",
       " 9: 3.29,\n",
       " 10: 1.9,\n",
       " 11: 1.87,\n",
       " 13: 2.06,\n",
       " 14: 1.07}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate VIF\n",
    "vif_dict = {val:round(variance_inflation_factor(df.loc[:, indep_vars].dropna(), idx), 2) for idx, val in enumerate(indep_vars)}\n",
    "vif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 out of 690 observations left after removing NAs (36 observations dropped)\n"
     ]
    }
   ],
   "source": [
    "#Drop NAs\n",
    "df_no_nas = df.dropna()\n",
    "print(f'{df_no_nas.shape[0]} out of {df.shape[0]} observations left after removing NAs ({df.shape[0] - df_no_nas.shape[0]} observations dropped)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove categorical variables\n",
    "df_no_cats = df_no_nas.loc[:, df_no_nas.nunique() > 2].copy()\n",
    "df_no_cats['Target'] = df_no_nas['Target'] #Retain target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_cats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info about final state of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_nas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5474006116207951"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get average of the target variable\n",
    "df_no_nas['Target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of categorical variables\n",
    "cat_vars_final_no = sum(df_no_nas.nunique() <= 2) - 1\n",
    "cat_vars_final_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of numerical variables\n",
    "df_no_nas.shape[1] - cat_vars_final_no - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0 observations dropped\n",
      "1: 13 observations dropped\n",
      "2: 7 observations dropped\n",
      "7: 5 observations dropped\n",
      "8: 0 observations dropped\n",
      "9: 0 observations dropped\n",
      "10: 7 observations dropped\n",
      "11: 0 observations dropped\n",
      "13: 7 observations dropped\n",
      "14: 7 observations dropped\n",
      "Total observations dropped: 46\n"
     ]
    }
   ],
   "source": [
    "#Trim outliers\n",
    "df_no_outs = df_no_nas.copy()\n",
    "for i in indep_vars:\n",
    "    mask = (df_no_outs[i] >= np.percentile(df_no_outs[i], 1)) & (df_no_outs[i] <= np.percentile(df_no_outs[i], 99))\n",
    "    print(f'{i}: {sum(np.invert(mask))} observations dropped')\n",
    "    df_no_outs = df_no_outs.loc[mask, :]\n",
    "print(f'Total observations dropped: {df_no_nas.shape[0] - df_no_outs.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export both versions of the data set\n",
    "df.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditApproval_nas.csv', index = False)\n",
    "df_no_nas.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditApproval_main.csv', index = False)\n",
    "df_no_cats.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditApproval_no_cats.csv', index = False)\n",
    "df_no_outs.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditApproval_no_outs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
