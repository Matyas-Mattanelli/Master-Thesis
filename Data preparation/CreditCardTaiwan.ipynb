{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_excel('D:/My stuff/School/Master/Master Thesis/Data/UCI Machine Learning Repository/Default of credit card clients Taiwan/default of credit card clients.xls', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the ID column\n",
    "df.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename target\n",
    "df.rename(columns = {'default payment next month' : 'Target'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop variables with a low fill rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns with percentage of missings higher than 0.2\n"
     ]
    }
   ],
   "source": [
    "#Drop variables with too many missing values\n",
    "miss_perc = df.isna().sum() / df.shape[0] > 0.2\n",
    "print(f'Dropped {sum(miss_perc)} columns with percentage of missings higher than 0.2')\n",
    "df = df.loc[:, np.invert(miss_perc)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retain categorical features with at most two unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 categorical features with more or less than 2 unique values\n"
     ]
    }
   ],
   "source": [
    "#Get number of unique values\n",
    "n_unique = df.nunique() #Get number of unique values (missings disregarded)\n",
    "cat_to_drop = (n_unique != 2) & (df.dtypes == 'object').values\n",
    "print(f'Dropping {sum(cat_to_drop)} categorical features with more or less than 2 unique values')\n",
    "df = df.loc[:, np.invert(cat_to_drop)] #Drop the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop education column (multiple values but integer encoded)\n",
    "df.drop('EDUCATION', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop marriage column (multiple values but integer encoded)\n",
    "df.drop('MARRIAGE', axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "df['SEX'] = df['SEX'].map({2 : 1, 1 : 0}, na_action = 'ignore')\n",
    "df.rename(columns = {'SEX' : 'FEMALE'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications\n",
    "dep_var = 'Target'\n",
    "thres = 0.75 #Arbitrary for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlations\n",
    "indep_vars = list(set(df.columns.to_list()) - set([dep_var])) #Specify the list of independent variables\n",
    "corr_mat = df.corr() #Calculate the correlation matrix\n",
    "dep_cor = corr_mat[dep_var].copy() #Extract the correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 0) #Drop the row with correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 1) #Drop the column with the correlations with the dependent variable\n",
    "corr_mat.values[np.tril_indices_from(corr_mat.values)] = np.nan #Leave only the upper triangle\n",
    "corr_mat = corr_mat.unstack().dropna().reset_index() #Unstack to a table\n",
    "corr_mat.columns = ['Var 1', 'Var 2', 'Corr'] #Rename columns for clarity\n",
    "corr_mat = corr_mat.loc[np.argsort(-corr_mat['Corr'].abs(), ), :].reset_index(drop = True) #Sort in absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable BILL_AMT2 dropped due to correlation of 95.15% with BILL_AMT1\n",
      "Variable BILL_AMT6 dropped due to correlation of 94.62% with BILL_AMT5\n",
      "Variable BILL_AMT5 dropped due to correlation of 94.01% with BILL_AMT4\n",
      "Variable BILL_AMT4 dropped due to correlation of 92.40% with BILL_AMT3\n",
      "Variable BILL_AMT3 dropped due to correlation of 89.23% with BILL_AMT1\n",
      "Variable PAY_5 dropped due to correlation of 81.98% with PAY_4\n",
      "Variable PAY_4 dropped due to correlation of 77.74% with PAY_3\n",
      "Variable PAY_3 dropped due to correlation of 76.66% with PAY_2\n",
      "Dropped 8 features due to high correlation\n"
     ]
    }
   ],
   "source": [
    "#Drop correlated features\n",
    "n_dropped = 0 #Initiate the number of dropped features\n",
    "for i in corr_mat.index[corr_mat['Corr'].abs() >= thres]: #Loop through all correlations higher than threshold (in absolute value)\n",
    "    var1, var2 = corr_mat.loc[i, 'Var 1'], corr_mat.loc[i, 'Var 2'] #Store variable names\n",
    "    if (var1 not in indep_vars) | (var2 not in indep_vars):\n",
    "        continue #Skip the iteration if one of the variables has already been disregarded\n",
    "    var_types = df.dtypes[[var1, var2]].to_list() #Store variable types\n",
    "    if var_types.count('object') == 1: #If only one of the variables is categorical, retain the numerical one\n",
    "        var_to_drop = [var1, var2][var_types.index('object')] #Store the categorical variable to drop\n",
    "        not_dropped_var = list(set([var1, var2]) - set(var_to_drop))[0] #Store the numerical variable to retain\n",
    "    else:\n",
    "        min_id = np.argmin(dep_cor[corr_mat.loc[i, ['Var 1', 'Var 2']].values].abs()) #Find the id of the variable with the smallest absolute correlation with the dependent variable\n",
    "        var_to_drop = corr_mat.loc[i, f'Var {min_id + 1}'] #Get the name of the variable to be dropped\n",
    "        not_dropped_var = corr_mat.loc[i, f'Var {abs(min_id - 2)}'] #Get the name of the variable that was not dropped (for logging purposes)\n",
    "    indep_vars.remove(var_to_drop) #Drop the variable\n",
    "    print(f'Variable {var_to_drop} dropped due to correlation of {corr_mat.loc[i, \"Corr\"]:.2%} with {not_dropped_var}')\n",
    "    n_dropped += 1\n",
    "print(f'Dropped {n_dropped} features due to high correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out dropped variables\n",
    "df = df.loc[:, indep_vars + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BILL_AMT1': 1.96,\n",
       " 'PAY_AMT4': 1.23,\n",
       " 'LIMIT_BAL': 3.78,\n",
       " 'PAY_AMT1': 1.32,\n",
       " 'PAY_6': 1.67,\n",
       " 'PAY_AMT6': 1.21,\n",
       " 'PAY_2': 2.29,\n",
       " 'FEMALE': 2.22,\n",
       " 'PAY_0': 1.89,\n",
       " 'PAY_AMT5': 1.22,\n",
       " 'PAY_AMT2': 1.24,\n",
       " 'PAY_AMT3': 1.27,\n",
       " 'AGE': 3.77}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate VIF\n",
    "vif_dict = {val:round(variance_inflation_factor(df.loc[:, indep_vars].dropna(), idx), 2) for idx, val in enumerate(indep_vars)}\n",
    "vif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 out of 30000 observations left after removing NAs (0 observations dropped)\n"
     ]
    }
   ],
   "source": [
    "#Drop NAs\n",
    "df_no_nas = df.dropna()\n",
    "print(f'{df_no_nas.shape[0]} out of {df.shape[0]} observations left after removing NAs ({df.shape[0] - df_no_nas.shape[0]} observations dropped)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove categorical variables\n",
    "df_no_cats = df_no_nas.loc[:, df_no_nas.nunique() > 2].copy()\n",
    "df_no_cats['Target'] = df_no_nas['Target'] #Retain target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_cats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info about final state of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_nas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get average of the target variable\n",
    "df_no_nas['Target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of categorical variables\n",
    "cat_vars_final_no = sum(df_no_nas.nunique() <= 2) - 1\n",
    "cat_vars_final_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of numerical variables\n",
    "df_no_nas.shape[1] - cat_vars_final_no - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILL_AMT1: 599 observations dropped\n",
      "PAY_AMT4: 294 observations dropped\n",
      "LIMIT_BAL: 148 observations dropped\n",
      "PAY_AMT1: 290 observations dropped\n",
      "PAY_6: 128 observations dropped\n",
      "PAY_AMT6: 286 observations dropped\n",
      "PAY_2: 144 observations dropped\n",
      "FEMALE: 0 observations dropped\n",
      "PAY_0: 53 observations dropped\n",
      "PAY_AMT5: 281 observations dropped\n",
      "PAY_AMT2: 278 observations dropped\n",
      "PAY_AMT3: 275 observations dropped\n",
      "AGE: 307 observations dropped\n",
      "Total observations dropped: 3083\n"
     ]
    }
   ],
   "source": [
    "#Trim outliers\n",
    "df_no_outs = df_no_nas.copy()\n",
    "for i in indep_vars:\n",
    "    mask = (df_no_outs[i] >= np.percentile(df_no_outs[i], 1)) & (df_no_outs[i] <= np.percentile(df_no_outs[i], 99))\n",
    "    print(f'{i}: {sum(np.invert(mask))} observations dropped')\n",
    "    df_no_outs = df_no_outs.loc[mask, :]\n",
    "print(f'Total observations dropped: {df_no_nas.shape[0] - df_no_outs.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export all versions of the data set\n",
    "df_no_nas.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditCardTaiwan_main.csv', index = False)\n",
    "df_no_cats.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditCardTaiwan_no_cats.csv', index = False)\n",
    "df_no_outs.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/CreditCardTaiwan_no_outs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
