{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('D:/My stuff/School/Master/Master Thesis/Data/Kaggle/Give me some credit/cs-training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the ID column\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns for clarity\n",
    "df.rename(columns = {'SeriousDlqin2yrs' : 'Target', 'age' : 'Age'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149999, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop observation with zero age\n",
    "df = df.loc[df['Age'] != 0, :]\n",
    "df.shape #Check shape after removal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop drop variables with a low fill rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target                                  0.000000\n",
       "RevolvingUtilizationOfUnsecuredLines    0.000000\n",
       "Age                                     0.000000\n",
       "NumberOfTime30-59DaysPastDueNotWorse    0.000000\n",
       "DebtRatio                               0.000000\n",
       "MonthlyIncome                           0.198208\n",
       "NumberOfOpenCreditLinesAndLoans         0.000000\n",
       "NumberOfTimes90DaysLate                 0.000000\n",
       "NumberRealEstateLoansOrLines            0.000000\n",
       "NumberOfTime60-89DaysPastDueNotWorse    0.000000\n",
       "NumberOfDependents                      0.026160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get percentage of missing values\n",
    "df.isna().sum() / df.shape[0] #Nothing higher than 20%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications\n",
    "dep_var = 'Target'\n",
    "thres = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlations\n",
    "indep_vars = list(set(df.columns.to_list()) - set([dep_var])) #Specify the list of independent variables\n",
    "corr_mat = df.corr() #Calculate the correlation matrix\n",
    "dep_cor = corr_mat[dep_var].copy() #Extract the correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 0) #Drop the row with correlations with the dependent variable\n",
    "corr_mat.drop(dep_var, axis = 1) #Drop the column with the correlations with the dependent variable\n",
    "corr_mat.values[np.tril_indices_from(corr_mat.values)] = np.nan #Leave only the upper triangle\n",
    "corr_mat = corr_mat.unstack().dropna().reset_index() #Unstack to a table\n",
    "corr_mat.columns = ['Var 1', 'Var 2', 'Corr'] #Rename columns for clarity\n",
    "corr_mat = corr_mat.loc[np.argsort(-corr_mat['Corr'].abs(), ), :].reset_index(drop = True) #Sort in absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable NumberOfTime60-89DaysPastDueNotWorse dropped due to correlation of 99.28% with NumberOfTimes90DaysLate\n",
      "Variable NumberOfTimes90DaysLate dropped due to correlation of 98.36% with NumberOfTime30-59DaysPastDueNotWorse\n",
      "Dropped 2 features due to high correlation\n"
     ]
    }
   ],
   "source": [
    "#Drop correlated features\n",
    "n_dropped = 0 #Initiate the number of dropped features\n",
    "for i in corr_mat.index[corr_mat['Corr'].abs() >= thres]: #Loop through all correlations higher than threshold (in absolute value)\n",
    "    if (corr_mat.loc[i, 'Var 1'] not in indep_vars) | (corr_mat.loc[i, 'Var 2'] not in indep_vars):\n",
    "        continue #Skip the iteration if one of the variables has already been disregarded\n",
    "    min_id = np.argmin(dep_cor[corr_mat.loc[i, ['Var 1', 'Var 2']].values].abs()) #Find the id of the variable with the smallest absolute correlation with the dependent variable\n",
    "    var_to_drop = corr_mat.loc[i, f'Var {min_id + 1}'] #Get the name of the variable to be dropped\n",
    "    indep_vars.remove(var_to_drop) #Drop the variable\n",
    "    not_dropped_var = corr_mat.loc[i, f'Var {abs(min_id - 2)}'] #Get the name of the variable that was not dropped (for logging purposes)\n",
    "    print(f'Variable {var_to_drop} dropped due to correlation of {corr_mat.loc[i, \"Corr\"]:.2%} with {not_dropped_var}')\n",
    "    n_dropped += 1\n",
    "print(f'Dropped {n_dropped} features due to high correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out dropped variables\n",
    "df = df.loc[:, indep_vars + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RevolvingUtilizationOfUnsecuredLines': 1.0,\n",
       " 'NumberOfDependents': 1.46,\n",
       " 'NumberRealEstateLoansOrLines': 2.3,\n",
       " 'MonthlyIncome': 1.24,\n",
       " 'DebtRatio': 1.01,\n",
       " 'Age': 3.91,\n",
       " 'NumberOfOpenCreditLinesAndLoans': 4.71,\n",
       " 'NumberOfTime30-59DaysPastDueNotWorse': 1.01}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check VIF\n",
    "{val:round(variance_inflation_factor(df.loc[:, indep_vars].dropna(), idx), 2) for idx, val in enumerate(indep_vars)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120268 out of 149999 observations left after removing NAs (29731 observations dropped)\n"
     ]
    }
   ],
   "source": [
    "#Drop NAs\n",
    "df_no_nas = df.dropna()\n",
    "print(f'{df_no_nas.shape[0]} out of {df.shape[0]} observations left after removing NAs ({df.shape[0] - df_no_nas.shape[0]} observations dropped)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove categorical variables\n",
    "df_no_cats = df_no_nas.loc[:, df_no_nas.nunique() > 2].copy()\n",
    "df_no_cats['Target'] = df_no_nas['Target'] #Retain target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120268, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_cats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info about final state of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120268, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "df_no_nas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06948648019423288"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get average of the target variable\n",
    "df_no_nas['Target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevolvingUtilizationOfUnsecuredLines: 1203 observations dropped\n",
      "NumberOfDependents: 911 observations dropped\n",
      "NumberRealEstateLoansOrLines: 663 observations dropped\n",
      "MonthlyIncome: 1068 observations dropped\n",
      "DebtRatio: 1164 observations dropped\n",
      "Age: 1897 observations dropped\n",
      "NumberOfOpenCreditLinesAndLoans: 1942 observations dropped\n",
      "NumberOfTime30-59DaysPastDueNotWorse: 1016 observations dropped\n",
      "Total observations dropped: 9864\n"
     ]
    }
   ],
   "source": [
    "#Trim outliers\n",
    "df_no_outs = df_no_nas.copy()\n",
    "for i in indep_vars:\n",
    "    mask = (df_no_outs[i] >= np.percentile(df_no_outs[i], 1)) & (df_no_outs[i] <= np.percentile(df_no_outs[i], 99))\n",
    "    print(f'{i}: {sum(np.invert(mask))} observations dropped')\n",
    "    df_no_outs = df_no_outs.loc[mask, :]\n",
    "print(f'Total observations dropped: {df_no_nas.shape[0] - df_no_outs.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export all versions of the data set\n",
    "df.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/GiveMeSomeCredit_nas.csv', index = False)\n",
    "df_no_nas.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/GiveMeSomeCredit_main.csv', index = False)\n",
    "df_no_outs.to_csv('D:/My stuff/School/Master/Master Thesis/Data/Final data/GiveMeSomeCredit_no_outs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
